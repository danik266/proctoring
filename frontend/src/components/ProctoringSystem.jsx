"use client";
import React, { useRef, useEffect, useState } from "react";
import * as faceapi from "@vladmandic/face-api";


const MODEL_URL = "https://vladmandic.github.io/face-api/model/";

export default function ProctoringSystem({ onViolation, isActive, sessionId }) {
  const videoRef = useRef(null);
  const streamRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]); 
  const sessionIdRef = useRef(sessionId);
  const cocoModelRef = useRef(null); // –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—Ñ –¥–ª—è –º–æ–¥–µ–ª–∏
  
  const lastViolationTime = useRef(0);
  const lastCheckTime = useRef(0);

  // –û–±–Ω–æ–≤–ª—è–µ–º ID –ø—Ä–∏ —Å–º–µ–Ω–µ –ø—Ä–æ–ø—Å–∞
  useEffect(() => {
    sessionIdRef.current = sessionId;
  }, [sessionId]);

 const saveAndUploadVideo = async (blob) => {
    if (!blob || blob.size === 0) return;

    const currentId = sessionIdRef.current;
    if (!currentId) {
        console.error("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–∏–≤—è–∑–∞—Ç—å –≤–∏–¥–µ–æ: sessionId –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.");
        return;
    }

    const formData = new FormData();
    // –ü–æ–ª–µ –¥–æ–ª–∂–Ω–æ –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è 'session_video', –∫–∞–∫ –≤ upload.single() –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
    formData.append("session_video", blob, `test_session_${currentId}.webm`);
    // –ü–æ–ª–µ sessionId –¥–ª—è —Å–≤—è–∑–∏ –≤ –ë–î
    formData.append("sessionId", currentId);

    try {
        const response = await fetch("http://localhost:5000/upload-video", {
            method: "POST",
            body: formData,
            // –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º keepalive –¥–ª—è —Ñ–∞–π–ª–æ–≤ > 64kb
        });
        
        if (response.ok) {
            const result = await response.json();
        } else {
            console.error("üì¶ –°–µ—Ä–≤–µ—Ä –ø—Ä–∏–Ω—è–ª —Ñ–∞–π–ª, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏–≤—è–∑–∫–∏.");
        }
    } catch (e) {
        console.error("üåê –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∏–¥–µ–æ:", e);
    }
  };
  // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.requestData(); // –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–∞–¥—Ä—ã
      mediaRecorderRef.current.stop(); // –≠—Ç–æ –≤—ã–∑–æ–≤–µ—Ç onstop
    }
  };

  // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã
  const stopCamera = () => {
     if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
     }
  };

  const startRecording = (stream) => {
    try {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º VP8 - –æ–Ω –ª—É—á—à–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –≤ –æ–±—ã—á–Ω—ã—Ö –ø–ª–µ–µ—Ä–∞—Ö
      const mimeType = 'video/webm; codecs=vp8'; 
      
      const options = MediaRecorder.isTypeSupported(mimeType) 
        ? { mimeType } 
        : { mimeType: 'video/webm' };

      const recorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = recorder;
      chunksRef.current = [];

      recorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      recorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: options.mimeType });
        chunksRef.current = []; // –ß–∏—Å—Ç–∏–º –ø–∞–º—è—Ç—å
        saveAndUploadVideo(blob);
        stopCamera(); // –í—ã–∫–ª—é—á–∞–µ–º –∫–∞–º–µ—Ä—É –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ —Å–±–æ—Ä–∫–∏ –≤–∏–¥–µ–æ
      };

      // –í–ê–ñ–ù–û: –£–±—Ä–∞–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç (1000). –ü–∏—à–µ–º –æ–¥–Ω–∏–º –∫—É—Å–∫–æ–º –≤ –ø–∞–º—è—Ç—å.
      // –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç "–±–∏—Ç—ã–µ" –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–∏ —Ä–∞–∑—Ä—ã–≤–µ.
      recorder.start(); 
    } catch (e) {
      console.error("–û—à–∏–±–∫–∞ —Å—Ç–∞—Ä—Ç–∞ –∑–∞–ø–∏—Å–∏:", e);
    }
  };

  // --- –õ–û–ì–ò–ö–ê –î–ï–¢–ï–ö–¶–ò–ò (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –∑–∞–Ω–∏–º–∞—Ç—å –º–µ—Å—Ç–æ) ---
  const startDetection = async () => {
    const run = async () => {
      if (!isActive || !videoRef.current) return;
      const now = Date.now();
      if (now - lastCheckTime.current > 100) {
          lastCheckTime.current = now;
          try {
             if (videoRef.current.readyState === 4) {
                 // –¢–≤–æ–π –∫–æ–¥ FaceAPI...
                 const detection = await faceapi.detectSingleFace(
                     videoRef.current, 
                     new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }) 
                 );
                 if (!detection) triggerViolation("–õ–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ");
                 
                 // –¢–≤–æ–π –∫–æ–¥ CocoSSD...
                 if (cocoModelRef.current) {
                     const objects = await cocoModelRef.current.detect(videoRef.current);
                     const forbidden = objects.find(obj => 
                         ["cell phone", "mobile phone", "laptop"].includes(obj.class) && obj.score > 0.5
                     );
                     if (forbidden) triggerViolation(`–ó–∞–ø—Ä–µ—â–µ–Ω–æ: ${forbidden.class}`);
                 }
             }
          } catch (e) { }
      }
      if (isActive) requestAnimationFrame(run);
    };
    run();
  };
  
  const triggerViolation = (reason) => {
      // –¢–≤–æ–π –∫–æ–¥ —Å–∫—Ä–∏–Ω–∞...
      const now = Date.now();
      if (now - lastViolationTime.current < 2000) return;
      lastViolationTime.current = now;
      onViolation(reason);
      
      // –°–∫—Ä–∏–Ω—à–æ—Ç—ã —Ç–æ–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
      if (videoRef.current) {
          const canvas = document.createElement("canvas");
          canvas.width = videoRef.current.videoWidth;
          canvas.height = videoRef.current.videoHeight;
          const ctx = canvas.getContext("2d");
          ctx.drawImage(videoRef.current, 0, 0);
          canvas.toBlob(b => {
             const fd = new FormData();
             fd.append("screenshot", b, `viol_${Date.now()}.jpg`);
             fetch("http://localhost:5000/upload-screenshot", { method: "POST", body: fd });
          });
      }
  };

  useEffect(() => {
    const init = async () => {
      // –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
      await Promise.all([
         faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
         cocoSsd.load()
      ]).then(([_, model]) => cocoModelRef.current = model);

      // –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã
      const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: true });
      streamRef.current = stream;
      if (videoRef.current) videoRef.current.srcObject = stream;

      startRecording(stream);
      startDetection();
    };

    init();

    // –ü–†–ò –í–´–•–û–î–ï
    return () => {
        // –ú—ã –≤—ã–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –æ—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–ø–∏—Å–∏.
        // –ö–∞–º–µ—Ä–∞ —Å–∞–º–∞ –≤—ã–∫–ª—é—á–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ recorder.onstop
        stopRecording();
    };
  }, []);

  return (
    <div style={styles.floatingBox}>
      <video ref={videoRef} autoPlay muted playsInline style={styles.video} />
      <div style={styles.statusDot}>REC</div>
    </div>
  );
}

const styles = {
  floatingBox: { position: "fixed", bottom: "24px", right: "24px", width: "180px", height: "135px", borderRadius: "12px", overflow: "hidden", zIndex: 1000, background: "#000", border: "2px solid #333" },
  video: { width: "100%", height: "100%", objectFit: "cover", transform: "scaleX(-1)" },
  statusDot: { position: "absolute", top: "8px", left: "8px", padding: "2px 6px", background: "red", color: "#fff", fontSize: "10px", fontWeight: "bold", borderRadius: "4px" }
};