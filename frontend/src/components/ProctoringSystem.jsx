"use client";
import React, { useRef, useEffect } from "react";
import * as faceapi from "@vladmandic/face-api";
import * as cocoSsd from "@tensorflow-models/coco-ssd";

const MODEL_URL = "https://vladmandic.github.io/face-api/model/";

export default function ProctoringSystem({ onViolation, isActive, sessionId }) {
  const videoRef = useRef(null);
  const streamRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]); 
  const sessionIdRef = useRef(sessionId);
  
  const cocoModelRef = useRef(null);
  const authorizedFaceRef = useRef(null); // –•—Ä–∞–Ω–∏—Ç –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä (—Å–ª–µ–ø–æ–∫) –ª–∏—Ü–∞ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

  const lastViolationTime = useRef(0);
  const lastCheckTime = useRef(0);

  useEffect(() => {
    sessionIdRef.current = sessionId;
  }, [sessionId]);

  // --- –ó–ê–ì–†–£–ó–ö–ê –í–ò–î–ï–û (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
  const saveAndUploadVideo = async (blob) => {
    if (!blob || blob.size === 0) return;
    const currentId = sessionIdRef.current;
    if (!currentId) return;

    const formData = new FormData();
    formData.append("session_video", blob, `test_session_${currentId}.webm`);
    formData.append("sessionId", currentId);

    try {
        await fetch("http://localhost:5000/upload-video", {
            method: "POST",
            body: formData,
        });
    } catch (e) {
        console.error("üåê –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ:", e);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.requestData();
      mediaRecorderRef.current.stop();
    }
  };

  const stopCamera = () => {
     if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
     }
  };

  const startRecording = (stream) => {
    try {
      const mimeType = 'video/webm; codecs=vp8'; 
      const options = MediaRecorder.isTypeSupported(mimeType) ? { mimeType } : { mimeType: 'video/webm' };
      const recorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = recorder;
      chunksRef.current = [];

      recorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) chunksRef.current.push(event.data);
      };

      recorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: options.mimeType });
        chunksRef.current = [];
        saveAndUploadVideo(blob);
        stopCamera();
      };
      recorder.start(); 
    } catch (e) {
      console.error("–û—à–∏–±–∫–∞ —Å—Ç–∞—Ä—Ç–∞ –∑–∞–ø–∏—Å–∏:", e);
    }
  };

  // --- –õ–û–ì–ò–ö–ê –ù–ê–†–£–®–ï–ù–ò–ô (–°–∫—Ä–∏–Ω—à–æ—Ç) ---
  const triggerViolation = async (reason) => {
    const now = Date.now();
    // –£–≤–µ–ª–∏—á–∏–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–æ 3 —Å–µ–∫, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –ø—Ä–∏ —Å–º–µ–Ω–µ –ª–∏—Ü–∞
    if (now - lastViolationTime.current < 3000) return; 
    lastViolationTime.current = now;

    let screenshotFilename = null;

    if (videoRef.current) {
        const canvas = document.createElement("canvas");
        canvas.width = videoRef.current.videoWidth;
        canvas.height = videoRef.current.videoHeight;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(videoRef.current, 0, 0);
        
        await new Promise(resolve => {
            canvas.toBlob(async (blob) => {
                const fd = new FormData();
                fd.append("screenshot", blob, `viol_${Date.now()}.jpg`);
                try {
                    const res = await fetch("http://localhost:5000/upload-screenshot", { method: "POST", body: fd });
                    const data = await res.json();
                    screenshotFilename = data.filename;
                } catch(e) { console.error(e); }
                resolve();
            });
        });
    }
    onViolation(reason, screenshotFilename);
  };

  // --- –ì–õ–ê–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–ï–¢–ï–ö–¶–ò–ò ---
  const startDetection = async () => {
    const run = async () => {
      if (!isActive || !videoRef.current) return;
      const now = Date.now();
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 200–º—Å (—á—É—Ç—å —Ä–µ–∂–µ, —Ç.–∫. –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ç—è–∂–µ–ª–µ–µ)
      if (now - lastCheckTime.current > 200) { 
          lastCheckTime.current = now;
          try {
             if (videoRef.current.readyState === 4) {
                 
                 // 1. –ü–û–ò–°–ö –õ–ò–¶ –ò –í–´–ß–ò–°–õ–ï–ù–ò–ï –î–ï–°–ö–†–ò–ü–¢–û–†–û–í
                 // –ò—Å–ø–æ–ª—å–∑—É–µ–º detectAllFaces, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π
                 const detections = await faceapi.detectAllFaces(
                     videoRef.current, 
                     new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }) 
                 )
                 .withFaceLandmarks() // –ù—É–∂–Ω–æ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
                 .withFaceDescriptors(); // –ù—É–∂–Ω–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (Face ID)

                 // –ü–†–û–í–ï–†–ö–ê 1: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π
                 if (detections.length === 0) {
                     triggerViolation("–õ–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ");
                 } else if (detections.length > 1) {
                     triggerViolation("–ü–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –≤ –∫–∞–¥—Ä–µ (–±–æ–ª–µ–µ 1 —á–µ–ª)");
                 } else {
                     // –ï—Å–ª–∏ –ª–∏—Ü–æ –æ–¥–Ω–æ - –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Ç–æ—Ç –ª–∏ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫
                     const currentDescriptor = detections[0].descriptor;

                     if (!authorizedFaceRef.current) {
                         // –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π —É—Å–ø–µ—à–Ω—ã–π –∫–∞–¥—Ä —Å –æ–¥–Ω–∏–º –ª–∏—Ü–æ–º - –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –µ–≥–æ
                         authorizedFaceRef.current = currentDescriptor;
                         console.log("‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω (–ª–∏—Ü–æ –∑–∞–ø–æ–º–Ω–µ–Ω–æ)");
                     } else {
                         // –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ª–∏—Ü–æ —Å –∑–∞–ø–æ–º–Ω–µ–Ω–Ω—ã–º
                         const distance = faceapi.euclideanDistance(authorizedFaceRef.current, currentDescriptor);
                         
                         // –ü–æ—Ä–æ–≥ 0.6 —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º –¥–ª—è face-api. 
                         // > 0.6 –∑–Ω–∞—á–∏—Ç –ª–∏—Ü–∞ —Ä–∞–∑–Ω—ã–µ.
                         if (distance > 0.6) {
                             triggerViolation("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ–¥–º–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è");
                         }
                     }
                 }
                 
                 // 2. –ü–û–ò–°–ö –û–ë–™–ï–ö–¢–û–í (CocoSSD)
                 if (cocoModelRef.current) {
                     const objects = await cocoModelRef.current.detect(videoRef.current);
                     const forbidden = objects.find(obj => 
                         ["cell phone", "mobile phone", "laptop"].includes(obj.class) && obj.score > 0.5
                     );
                     if (forbidden) triggerViolation(`–ó–∞–ø—Ä–µ—â–µ–Ω–æ: ${forbidden.class}`);
                 }
             }
          } catch (e) { 
              console.error("Detection error:", e);
          }
      }
      if (isActive) requestAnimationFrame(run);
    };
    run();
  };
  
  useEffect(() => {
    const init = async () => {
      try {
          // –ó–∞–≥—Ä—É–∂–∞–µ–º –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
          await Promise.all([
             faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
             faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL), // –î–ª—è —Ç–æ—á–µ–∫ –ª–∏—Ü–∞
             faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL), // –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü
             cocoSsd.load()
          ]).then(([_, __, ___, model]) => cocoModelRef.current = model);

          const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: true });
          streamRef.current = stream;
          if (videoRef.current) videoRef.current.srcObject = stream;

          startRecording(stream);
          startDetection();
      } catch (e) {
          console.error("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:", e);
      }
    };

    init();

    return () => {
        stopRecording();
    };
  }, []);

  return (
    <div style={styles.floatingBox}>
      <video ref={videoRef} autoPlay muted playsInline style={styles.video} />
      <div style={styles.statusDot}>REC</div>
    </div>
  );
}

const styles = {
  floatingBox: { position: "fixed", bottom: "24px", right: "24px", width: "180px", height: "135px", borderRadius: "12px", overflow: "hidden", zIndex: 1000, background: "#000", border: "2px solid #333" },
  video: { width: "100%", height: "100%", objectFit: "cover", transform: "scaleX(-1)" },
  statusDot: { position: "absolute", top: "8px", left: "8px", padding: "2px 6px", background: "red", color: "#fff", fontSize: "10px", fontWeight: "bold", borderRadius: "4px" }
};